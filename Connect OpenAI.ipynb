{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4ced59",
   "metadata": {},
   "source": [
    "# Set up your OpenAI Account \n",
    "\n",
    "- If you don't have an API key, sign up for OpenAI https://platform.openai.com/ and obtain one.\n",
    "- Store your API key in a secure location, such as a configuration file or environment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d201c4",
   "metadata": {},
   "source": [
    "### Install the OpenAI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b2adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0398c",
   "metadata": {},
   "source": [
    "### Import OpenAI library\n",
    "- I have stored my API key in a configuration file OpenAPIkey.py\n",
    "- You can set up enviroment variable for OpenAI key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e7faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "from OpenAPIKey import api_key # importing an openAI key form OpenAPIKey config file.\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4522ecf",
   "metadata": {},
   "source": [
    "### Helper Function \n",
    "- We will use OpenAI's gpt-3.5-turbo model and the chat completions endpoint.\n",
    "- This helper function will make it easier to use prompts and look at the generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81744fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(prompt,model = 'gpt-3.5-turbo'):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "     model=model,\n",
    "     messages=messages,\n",
    "     temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77578d",
   "metadata": {},
   "source": [
    "### Detailed Explanation of above listed function \n",
    "\n",
    "- The <b>prompt</b> parameter represents the user's input or message that will be used to generate a response from the model.\n",
    "\n",
    "- The <b>model</b> parameter is optional and specifies the model to be used. By default, it is set to \"gpt-3.5-turbo,\" which is a powerful language model provided by OpenAI. You can change the model to use a different one if desired.\n",
    "\n",
    "- The <b>messages</b> variable is a list of message objects that will be used as the conversation history for the model. In this case, it contains a single message with the role \"user\" and the content of the user's input or prompt.\n",
    "\n",
    "- The <b>openai.ChatCompletion.create()</b> method is called to generate a completion. It takes the model and messages as inputs.\n",
    "\n",
    "- The <b>temperature</b> parameter controls the randomness of the model's output. A higher value, such as 0.8, would result in more diverse and creative responses, while a lower value like 0 would make the responses more focused and deterministic.\n",
    "\n",
    "### The completion response is stored in the response variable.\n",
    "\n",
    "- The function returns the content of the model's response by accessing <b> response.choices[0].message[\"content\"]</b>. This retrieves the content of the first message in the response choices, which represents the generated completion or response from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474f45b",
   "metadata": {},
   "source": [
    "### Lets Start a Sample Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d617b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"players\": [\n",
      "    {\n",
      "      \"Name\": \"Sachin Tendulkar\",\n",
      "      \"Number_of_Matches\": {\n",
      "        \"ODI\": 463,\n",
      "        \"Test\": 200\n",
      "      },\n",
      "      \"Runs\": {\n",
      "        \"ODI\": 18426,\n",
      "        \"Test\": 15921\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Name\": \"Rahul Dravid\",\n",
      "      \"Number_of_Matches\": {\n",
      "        \"ODI\": 344,\n",
      "        \"Test\": 164\n",
      "      },\n",
      "      \"Runs\": {\n",
      "        \"ODI\": 10889,\n",
      "        \"Test\": 13288\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Name\": \"Virat Kohli\",\n",
      "      \"Number_of_Matches\": {\n",
      "        \"ODI\": 254,\n",
      "        \"Test\": 92\n",
      "      },\n",
      "      \"Runs\": {\n",
      "        \"ODI\": 12169,\n",
      "        \"Test\": 7547\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt  = f\"\"\"\n",
    "Generate a list of three well known indian cricketers\\\n",
    "with their Total Run scored in ODI and Test Cricket.\n",
    "Provide them in JSON format with the following keys:\n",
    "Name,Number_of_Matches,Runs.\n",
    "\"\"\"\n",
    "response = get_output(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
